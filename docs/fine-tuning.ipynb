{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93937930-2426-4cfa-a8fb-83ef6171cb11",
   "metadata": {},
   "source": [
    "## __Statistical and Linguistic Insights for Model Explanation - SLIME__ \n",
    "### __Fine-tuning custom LLM for classification__\n",
    "<font size=3>\n",
    "\n",
    "To enhance the LLM for classification tasks, we can adapt the $\\mathtt{CustomModel}$ class to perform neural network (NN) modeling using the following approaches:\n",
    "\n",
    "Use the $\\mathtt{FitModel().fit()}$ method when the dataset is sufficiently large for both training and validation.\n",
    "Use the $\\mathtt{FitModel().kfold()}$ method when the dataset is too small to split directly into training and validation sets.\n",
    "After completing the NN modeling, the final training step is performed using the $\\mathtt{FitModel().fit()}$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab6a44e-a895-4182-bf5d-452d9394bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9cd509e-a6a0-41fb-9171-21574f635a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slime_nlp.dataset import ImportData\n",
    "from slime_nlp.model import CustomModel, FitModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55b26c-6d6f-4642-8c6d-65f12000af29",
   "metadata": {},
   "source": [
    "### __1. Fine-tuning: for train and validation data__\n",
    "<font size=3>\n",
    "\n",
    "- Using $\\mathtt{ImportData}$ to split the dataset into train, validation, and test data;\n",
    "- Using $\\mathtt{FitModel.fit()}$ for train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d68d6c-1225-4679-974a-64dfeb71e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                                 text  group\n",
      "0  oh there's a cookie jar and a youngster with a...      1\n",
      "1  cookie jar . <filler> a lad standing on a stoo...      0\n",
      "2  well the table stool sr-ret <retracing> the se...      1\n",
      "\n",
      "Data length: N_total = 5\n",
      "N-train = 5, N-val = 0, N-test = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id = ImportData(path_name=\"../dataset/adress_sample.csv\", n_val=0.15, n_test=0.1, \n",
    "                group_by=['text', 'group'], verbose=True)\n",
    "\n",
    "train_data = id.train\n",
    "val_data = id.val\n",
    "test_data = id.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a55f1541-d2d3-4761-bcec-0dcd36e46d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # FitModel: CustomModel model fitting.\n",
      "\n",
      "    Input: (device='cpu', optimizer='AdamW', lr=2e-5, lr_sub=2e-4, eps=1e-8)\n",
      "    -----\n",
      "    - device (str): select CPU or GPU for training.\n",
      "    - optimizer (str): training optimizer name.\n",
      "    - lr (float): learning-rate for AutoModel's LLM weights adjustment.\n",
      "    - lr_sub (float): learning-rate for weights adjustment of the CustomModel's \n",
      "    additional layer block.\n",
      "    - eps (float): optimizer constant for numerical stability.\n",
      "\n",
      "    Methods:\n",
      "    -------\n",
      "    - train_step (X, y):\n",
      "      -- X (Tensor): CustomModel input data.\n",
      "      -- y (Tensor): tensor of numerical labels.\n",
      "\n",
      "      Returns (Tensor) the loss function value.\n",
      "\n",
      "    - fit (train_data, val_data=None, epochs=1, batch_size=1, pretrained_name=\"google-bert/bert-base-cased\",\n",
      "    klabel='', path_name=None, patience=0, min_delta=1e-2):\n",
      "      -- train_data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) \n",
      "      and \"group\"(int) columns.\n",
      "      -- val_data (Dataframe): equivalent to train_data.\n",
      "      -- epochs (int): number of epochs for training.\n",
      "      -- batch_size (int): data batch-size value.\n",
      "      -- pretained_name (str): pretrained model name from huggingface.co repository.\n",
      "      -- klabel (str): string argument for kfold() method.\n",
      "      -- path_name (srt): path and model name string for saving.\n",
      "      -- patience (int): number of epochs to wait for the early-stop mechanism. For\n",
      "      patience=0, the early-stop is not considered.\n",
      "      -- min_delta (float): tolerance value above the best metric result during the training. \n",
      "      If no improvement is achieved, the training is stopped.\n",
      "\n",
      "    - kfold (data, K=2, epochs=1, batch_size=1, model_name=None, pretrained_name=\"google-bert/bert-base-cased\"):\n",
      "      -- data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) \n",
      "      and \"group\"(int) columns.\n",
      "      -- K (int): number of folds for cross-validation.\n",
      "      -- epochs (int): number of epochs for each cross-validation loop.\n",
      "      -- batch_size (int): data batch-size value.\n",
      "      -- model_name (srt): path and model name string for saving.\n",
      "      -- pretained_name (str): pretrained model name from huggingface.co repository.\n",
      "\n",
      "    - plot_metric (path_name=None):\n",
      "      -- path_name (srt): path and plot name string for saving.\n",
      "      \n",
      "      Returns the plot of the loss function values and metrics during training.\n",
      "      \n",
      "    - fold_evaluation:\n",
      "      Evaluates the performance of the K-fold cross-validation.\n",
      "\n",
      "    - evaluate (data):\n",
      "      -- data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) \n",
      "      and \"group\"(int) columns.\n",
      "\n",
      "      Returns the mean values of the F1-score and Accuracy metrics. \n",
      "\n",
      "    - save (path_name=\"weights/model_weights.pt\"):\n",
      "      -- model_name (srt): path and model name string for saving.\n",
      "\n",
      "      Creates the \"weights\" directory and saves the model's inner parameters.\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "fm = FitModel(device='cpu')\n",
    "\n",
    "print(fm.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb680e2-a80d-4cc7-82cd-9299b05ad8d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64e0e5a4de64eb28c3aeca734279bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 1/1:\n",
      "Batch:80% - <train-loss> = 7.189e-01\n"
     ]
    }
   ],
   "source": [
    "fm.fit(train_data, val_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866436c5-3c10-40c8-b77c-a11cdfd78c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.plot_metric() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfaaf0-c9a5-4463-8196-426d7ec25102",
   "metadata": {},
   "source": [
    "### __2. Fine-tuning: for K-fold cross-validation.__\n",
    "<font size=3>\n",
    "\n",
    "- Using $\\mathtt{ImportData}$ to split the dataset into train and test data;\n",
    "- Using $\\mathtt{FitModel.kfold()}$ for K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c2dcac7-a92f-4aba-b0f7-88dfd5261c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                                 text  group\n",
      "0  oh there's a cookie jar and a youngster with a...      1\n",
      "1  cookie jar . <filler> a lad standing on a stoo...      0\n",
      "2  well the table stool sr-ret <retracing> the se...      1\n",
      "\n",
      "Data length: N_total = 5\n",
      "N-train = 5, N-val = 0, N-test = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id = ImportData(path_name=\"../dataset/adress_sample.csv\", n_val=0.0, n_test=0.1,\n",
    "                group_by=['text', 'group'], verbose=True)\n",
    "\n",
    "train_data = id.train\n",
    "test_data = id.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e39b3e-57f2-41b6-ae90-1fee8cfff372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fm = FitModel(device='cpu')\n",
    "\n",
    "fm.kfold(train_data, K=5, batch_size=2, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.plot_metric() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853a8fd-5b22-4d02-86ae-1759fd2c6cc5",
   "metadata": {},
   "source": [
    "### __3. Fine-tuning: for final training after NN modeling.__\n",
    "<font size=3>\n",
    "\n",
    "- Using $\\mathtt{ImportData}$ to split the dataset into train and test data;\n",
    "- Using $\\mathtt{FitModel.fit()}$ for final training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884d4b15-7d6c-4825-b240-12dda5d17646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                                 text  group\n",
      "0  well the little girl is saying to be uiet to h...      0\n",
      "1  mhm . well the water's running over on the flo...      0\n",
      "2  look at the picture <unintelligible> . oh okay...      0\n",
      "\n",
      "Data length: N_total = 156\n",
      "N-train = 141, N-val = 0, N-test = 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id = ImportData(path_name=\"../dataset/adress_sample.csv\", n_val=0.0, n_test=0.1,\n",
    "                group_by=['text', 'group'], verbose=True)\n",
    "\n",
    "train_data = id.train\n",
    "test_data = id.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c6ef1-3db3-4b9c-8b35-75bbb1d45ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fm = FitModel(device='cpu')\n",
    "\n",
    "fm.fit(train_data, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f239-f3a3-4f43-ac48-6fa7e61d3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943a04d-269d-41f0-a610-6a5131a38e9e",
   "metadata": {},
   "source": [
    "### __4. Making predictions:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426c2696-6a95-4f49-a2f4-f84c9f07d83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # CustomModel: Custom LLM for classification\n",
      "\n",
      "    Input: (pretrained_name=\"google-bert/bert-base-cased\")\n",
      "    ----- \n",
      "    - pretained_name (str): pretrained model name from huggingface.co repository.\n",
      "\n",
      "    Returns object with callable model's input.\n",
      "\n",
      "    \n",
      "    Methods:\n",
      "    -------\n",
      "    - forward = __call__: (input_ids, token_type_ids=None, attention_mask=None)\n",
      "      -- input_ids (Tensor[int]): sequence of special tokens IDs.\n",
      "      -- token_type_ids (Tensor[int]): sequence of token indices to distinguish \n",
      "      between sentence pairs.\n",
      "      -- attention_mask (Tensor[int]): mask to avoid performing attention on padding \n",
      "      token indices.\n",
      "\n",
      "      Returns a Tensor with linear prediction output.\n",
      "    \n",
      "    - load: (path_name=\"weights/model_weights.pt\", device='cpu') \n",
      "      Loads model's weights.\n",
      "      \n",
      "      -- path_name (str): string with path and name of the model's weights (.pt)\n",
      "      for saving.\n",
      "      -- device (str): select CPU or GPU for prediction processing.\n",
      "    \n",
      "    - predict: (data)\n",
      "      -- data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) \n",
      "      and \"group\"(int) columns.\n",
      "\n",
      "      Returns (Tensor[float]) a tensor with prediction scalars (0, 1).\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model = CustomModel().to('cpu')\n",
    "\n",
    "print(model.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46cd729b-bd3a-46ce-963d-65fa84eb1d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../weights/best_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[0;32m~/Desktop/SLIME/pySSMeD-main/slime_nlp/docs/../slime_nlp/model.py:93\u001b[0m, in \u001b[0;36mCustomModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     91\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 93\u001b[0m dset \u001b[38;5;241m=\u001b[39m CustomDset(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__device)\n\u001b[1;32m     95\u001b[0m pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dset:        \n",
      "File \u001b[0;32m~/Desktop/SLIME/pySSMeD-main/slime_nlp/docs/../slime_nlp/dataset.py:103\u001b[0m, in \u001b[0;36mCustomDset.__init__\u001b[0;34m(self, data, max_length, batch_size, shuffle, device, pretrained_name)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, max_length, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle-bert/bert-base-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle: data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[pt\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(data))]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "model.load(\"../weights/best_model.pt\")\n",
    "\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd10cd2-1692-43f8-8441-f28e1093028c",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/v4.45.2/en/model_doc/auto#transformers.AutoConfig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
