{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93937930-2426-4cfa-a8fb-83ef6171cb11",
   "metadata": {},
   "source": [
    "## __Statistical and Linguistic Insights for Model Explanation - SLIME__ \n",
    "### __Importing dataset and preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc769342-c585-4156-b42d-44e7b003bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656eab6c-e42d-4ace-8da0-230e5ab3fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slime_nlp.dataset import ImportData, CustomDset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04064590-dd0e-48f9-a518-4fc7710dccbb",
   "metadata": {},
   "source": [
    "### __1. $\\mathtt{ImportData}$:__\n",
    "<font size=3>\n",
    "    \n",
    "Import dataset (.csv) to split the data into train, validation, and test dataframes. \\\n",
    "_Check the ImportData object's doc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ff59bd-755c-4904-bf41-c13b0d46b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                                 text  group\n",
      "0  oh there's a cookie jar and a youngster with a...      1\n",
      "1  cookie jar . <filler> a lad standing on a stoo...      0\n",
      "2  well the table stool sr-ret <retracing> the se...      1\n",
      "\n",
      "Data length: N_total = 5\n",
      "N-train = 5, N-val = 0, N-test = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id = ImportData(path_name=\"../dataset/adress_sample.csv\", \n",
    "                n_val=0.15, n_test=0.10, \n",
    "                group_by=['text', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75f68eb-6102-439a-b34c-22baf304e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # ImportData: import dataframe and split it into train, validation, and test data.\n",
      "    \n",
      "    Input: (path_name, n_val=None, n_test=None, group_by=None, verbose=True)\n",
      "    -----\n",
      "    - path_name (str): string with path and data name.\n",
      "    - n_val (float): quantile of validation data.\n",
      "    - n_test (float): quantile of test data.\n",
      "    - group_by (List[str]): list of the dataframe's column names to group by.\n",
      "    - verbose (bool): boolean variable to print dataset info.\n",
      "\n",
      "\n",
      "    Attributes: \n",
      "    ----------\n",
      "    - train (Dataframe): pandas dataframe of train batch.\n",
      "    - val (Dataframe): pandas dataframe of validation batch.\n",
      "    - test (Dataframe): pandas dataframe of test batch.\n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(id.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a77d90e-b051-4dc4-8274-247bef210139",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m val_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mval\n\u001b[1;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mtest\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData shape = train:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - validation:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - test:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_data = id.train\n",
    "val_data = id.val\n",
    "test_data = id.test\n",
    "\n",
    "print(f\"Data shape = train:{train_data.shape} - validation:{val_data.shape} - test:{test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b8c5b98-dfcd-4c10-ac4e-bdae9dc67a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookie jar . &lt;filler&gt; a lad standing on a stoo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay the water's running outof the sink overfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh there's a cookie jar and a youngster with a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well the table stool sr-ret &lt;retracing&gt; the se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mhm . there's a young boy &lt;filler&gt; going in a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  group\n",
       "1  cookie jar . <filler> a lad standing on a stoo...      0\n",
       "4  okay the water's running outof the sink overfl...      0\n",
       "0  oh there's a cookie jar and a youngster with a...      1\n",
       "2  well the table stool sr-ret <retracing> the se...      1\n",
       "3  mhm . there's a young boy <filler> going in a ...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc9bdf-6852-433d-b670-331073bd2751",
   "metadata": {},
   "source": [
    "### __2. $\\mathtt{CustomDset}$:__\n",
    "<font size=3>\n",
    "    \n",
    "Tokenizing the data sentences to return the model's input tensors (_input_ids, token_type_ids, attention_mask_), and the label tensor (_groups condition and control_). \\\n",
    "_Check the CustomDset object's doc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1964adc9-e14a-469a-a47b-ed686179c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = CustomDset(data=train_data, max_length=512, \n",
    "                        batch_size=1, shuffle=True, device=\"cpu\", \n",
    "                        pretrained_name=\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffceb396-77b5-4104-96d3-0b2e99831c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # CustomDset: import the data sentences to return a PyTorch generator of tokenized \n",
      "    tensors.\n",
      "\n",
      "    Input: (data, max_length, batch_size=1, shuffle=True, device='cpu',\n",
      "            pretrained_name=\"google-bert/bert-base-cased\")\n",
      "    ----- \n",
      "    - data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) and \n",
      "    \"group\"(int) columns.\n",
      "    - max_length (int): the sequence maximum length.\n",
      "    - batch_size (int): data batch-size value.\n",
      "    - shuffle (bool): boolean variable for data shuffling.\n",
      "    - device (str): select CPU or GPU device for output tensors.\n",
      "    - pretained_name (str): pretrained model name from huggingface.co repository.\n",
      "\n",
      "\n",
      "    Methods:\n",
      "    -------\n",
      "    __len__ (int): returns data size.\n",
      "    \n",
      "    __getitem__ (Tuple[Tensor, Tensor, Tensor], Tensor): generator \n",
      "    \n",
      "    \n",
      "    Output (generator): (input_ids, token_type_ids, attention_mask), label\n",
      "    ------ \n",
      "    - input_ids (Tensor[int]): sequence of special tokens IDs.\n",
      "    - token_type_ids (Tensor[int]): sequence of token indices to distinguish between \n",
      "    sentence pairs.\n",
      "    - attention_mask (Tensor[int]): mask to avoid performing attention on padding token \n",
      "    indices.\n",
      "    - label (Tensor): the corresponding label for the input sequence.\n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(train_dset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "892f6d94-ab1c-429e-897c-71b6c202a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data size:\", len(train_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c2e87ef-c79b-411f-a515-30e0c35c2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 223])\n",
      "token_type_ids: torch.Size([1, 223])\n",
      "attention_mask: torch.Size([1, 223])\n",
      "label: tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "(input_ids, token_type_ids, attention_mask), label = train_dset.__getitem__(index=0)\n",
    "\n",
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"token_type_ids:\", token_type_ids.shape)\n",
    "print(\"attention_mask:\", attention_mask.shape)\n",
    "print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d58b2e-ed30-47a3-b70d-1fc1dd50e850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
