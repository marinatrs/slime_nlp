{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93937930-2426-4cfa-a8fb-83ef6171cb11",
   "metadata": {},
   "source": [
    "## __Statistical and Linguistic Insights for Model Explanation - SLIME__ \n",
    "### __Importing dataset and preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656eab6c-e42d-4ace-8da0-230e5ab3fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from slime_nlp.dataset import ImportData, CustomDset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04064590-dd0e-48f9-a518-4fc7710dccbb",
   "metadata": {},
   "source": [
    "### __1. $\\mathtt{ImportData}$:__\n",
    "<font size=3>\n",
    "    \n",
    "Import dataset (.csv) to split the data into train, validation, and test dataframes. \\\n",
    "_Check the ImportData object's doc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ff59bd-755c-4904-bf41-c13b0d46b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "                                                 text  group\n",
      "0  well the little girl is saying to be uiet to h...      0\n",
      "1  mhm . well the water's running over on the flo...      0\n",
      "2  look at the picture <unintelligible> . oh okay...      0\n",
      "\n",
      "Data length: N_total = 156\n",
      "N-train = 118, N-val = 23, N-test = 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id = ImportData(path_name=\"../dataset/adress_all.csv\", \n",
    "                n_val=0.15, n_test=0.10, \n",
    "                group_by=['text', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75f68eb-6102-439a-b34c-22baf304e12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # ImportData: import dataframe and split it into train, validation, and test data.\n",
      "    \n",
      "    Input: (path_name, n_val=None, n_test=None, group_by=None, verbose=True)\n",
      "    -----\n",
      "    - path_name (str): string with the path and data name;\n",
      "    - n_val (float): quantile of validation data;\n",
      "    - n_test (float): quantile of test data;\n",
      "    - group_by (List[str]): list of the dataframe's column names to be grouped.\n",
      "    - verbose (bool): boolean variable to print dataset info.\n",
      "\n",
      "\n",
      "    Attributes: \n",
      "    ----------\n",
      "    - train (Dataframe): pandas dataframe of train batch;\n",
      "    - val (Dataframe): pandas dataframe of validation batch;\n",
      "    - test (Dataframe): pandas dataframe of test batch.\n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(id.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a77d90e-b051-4dc4-8274-247bef210139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape = train:(118, 2) - validation:(23, 2) - test:(15, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = id.train\n",
    "val_data = id.val\n",
    "test_data = id.test\n",
    "\n",
    "print(f\"Data shape = train:{train_data.shape} - validation:{val_data.shape} - test:{test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8c5b98-dfcd-4c10-ac4e-bdae9dc67a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>well the sink is running over . she's drying t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>&lt;event&gt; &lt;filler&gt; the woman of the house is dry...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>you mean right now tell you . &lt;filler&gt; the boy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>well your sink is being run over the water . t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>okay the water's running outof the sink overfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  group\n",
       "121  well the sink is running over . she's drying t...      1\n",
       "79   <event> <filler> the woman of the house is dry...      1\n",
       "29   you mean right now tell you . <filler> the boy...      0\n",
       "84   well your sink is being run over the water . t...      1\n",
       "153  okay the water's running outof the sink overfl...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc9bdf-6852-433d-b670-331073bd2751",
   "metadata": {},
   "source": [
    "### __2. $\\mathtt{CustomDset}$:__\n",
    "<font size=3>\n",
    "    \n",
    "Tokenizing the data sentences to return the model's input tensors (_input_ids, token_type_ids, attention_mask_), and the label tensor (_groups Alzheimer's disease and control_). \\\n",
    "_Check the CustomDset object's doc._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1964adc9-e14a-469a-a47b-ed686179c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = CustomDset(data=train_data, max_length=512, \n",
    "                        batch_size=1, shuffle=True, device=\"cpu\", \n",
    "                        pretrained_name=\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffceb396-77b5-4104-96d3-0b2e99831c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    # CustomDset: import the data sentences to return a PyTorch generator of tokenized \n",
      "    tensors of batch-size = 1.\n",
      "\n",
      "    Input: (data, max_length, device='cpu')\n",
      "    ----- \n",
      "    - data (Dataframe): pandas dataframe (ImportData's output) with \"text\"(str) and \n",
      "    \"group\"(int) columns.\n",
      "    - max_length (int): the sequence maximum length.\n",
      "    - batch_size (int): data batch-size value.\n",
      "    - shuffle (bool): boolean variable for data shuffling.\n",
      "    - device (str): select CPU or GPU device for output tensors.\n",
      "    - pretained_name (str): pretrained model name from huggingface.co repository.\n",
      "\n",
      "\n",
      "    Methods:\n",
      "    -------\n",
      "    __len__ (int): returns data size.\n",
      "    \n",
      "    __getitem__ (Tuple[Tensor, Tensor, Tensor], Tensor): generator \n",
      "    \n",
      "    \n",
      "    Output (generator): (input_ids, token_type_ids, attention_mask), label\n",
      "    ------ \n",
      "    - input_ids (Tensor): sequence of special tokens IDs.\n",
      "    - token_type_ids (Tensor): sequence of token indices to distinguish between \n",
      "    sentence pairs.\n",
      "    - attention_mask (Tensor): mask to avoid performing attention on padding token \n",
      "    indices.\n",
      "    - label (Tensor): the corresponding label for the input sequence.\n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(train_dset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892f6d94-ab1c-429e-897c-71b6c202a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 118\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data size:\", len(train_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2e87ef-c79b-411f-a515-30e0c35c2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 249])\n",
      "token_type_ids: torch.Size([1, 249])\n",
      "attention_mask: torch.Size([1, 249])\n",
      "label: tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "(input_ids, token_type_ids, attention_mask), label = train_dset.__getitem__(index=0)\n",
    "\n",
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"token_type_ids:\", token_type_ids.shape)\n",
    "print(\"attention_mask:\", attention_mask.shape)\n",
    "print(\"label:\", label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
